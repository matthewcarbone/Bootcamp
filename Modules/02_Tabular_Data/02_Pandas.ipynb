{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f794b95-c3a7-4900-8b29-5f0d9da8277b",
   "metadata": {},
   "source": [
    "# Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf96a06-8068-4e89-8093-9f7a228388a9",
   "metadata": {},
   "source": [
    "In this notebook, we're going to introduce [Pandas](https://pandas.pydata.org/), an \"open source data analysis and manipulation tool.\" It is, effectively, an extension of the capabilities of NumPy, with a particular focus on two-dimensional data. Check out their [library highlights](https://pandas.pydata.org/about/) for some specific details on what sets Pandas apart from other tools, including NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ba776-953b-488a-adb1-71f7e431d3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # similar import abbreviation to NumPy (np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f820383-493c-4488-af13-53dff88176a7",
   "metadata": {},
   "source": [
    "To demonstrate the power and utility of Pandas, we're going to use an existing popular open-source dataset. To access it, we first need to install the `huggingface_hub` Python package via `pip`, lets do that first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43b137-2aff-48f7-81d3-78feca4fb040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qqq huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b43c1-63f8-416b-a21a-6642e92639b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hf://datasets/leostelon/california-housing/housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d161b-aaf6-4dfc-b4b8-334a8afa9ad2",
   "metadata": {},
   "source": [
    "Once we have the data, the first step is to get a feel for what it looks like. We can do this with a very useful method: `head`. This truncates the database to only its first five rows (by default). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf0b106-8cb0-4d30-835b-68e36a8b241c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0127956-386d-439f-9573-1d8f399be670",
   "metadata": {},
   "source": [
    "With this, we can get an idea of what we're dealing with. Most columns are numeric values (with one text value in the last column). The rest of this notebook will be dedicated to understanding this dataset using various Pandas methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469fe7c-bc32-4792-aeef-ef886a464c15",
   "metadata": {},
   "source": [
    "# The dataframe and basic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defad90b-f6bf-4a69-b828-f16c8d11b6b7",
   "metadata": {},
   "source": [
    "The [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) is essentially a NumPy array, with a few extra bells and whistles. First, and most importantly, it can be heterogeneous. Remember when NumPy tried to cast everything in the array to a common data type? Pandas does not do this. Instead, each column can be a different data type, and Pandas is smart enough to know which methods work on which columns and which do not. The DataFrame, unlike a NumPy array, is two-dimensional. Above, you have already seen your first DataFrame, `df`.\n",
    "\n",
    "Before diving into the vast number of ways to manipulate DataFrames, let's first focus on the ways we can summarize them. This [blog post](https://medium.com/analytics-vidhya/how-to-summarize-data-with-pandas-2c9edffafbaf) does a good job of listing many of these methods. Here, we will examine a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a39c00-899f-4828-a745-43577ecaf54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff70c06-3dc7-4eb4-9127-7a120ffac038",
   "metadata": {},
   "source": [
    "The `info` method provides some nice information in plaintext form about the columns in the data frame, the types of data in each column, and the total memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277158db-4287-4703-98c2-4d9e4463ed29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa2961-1cab-4ccb-a2ab-4b16a2b2ebce",
   "metadata": {},
   "source": [
    "The `describe` method takes the numeric columns, and produces the total non-NaN (null) counts, mean, standard deviation, minimum, maxmimum and quartiles of each column. It is a useful summary of the statistics of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816b21e-d3a8-4007-a610-505905862bf7",
   "metadata": {},
   "source": [
    "## DataFrame io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a7514-a71d-41e5-bb86-a4e57ee896aa",
   "metadata": {},
   "source": [
    "A DataFrame is tabular data, same as any `.csv` file you might read using Microsoft Excel. As such, Pandas provides a few useful methods for writing and reading DataFrames to disk. It is useful to go over and understand these right away, since what good is your data analysis if you cannot save it?\n",
    "\n",
    "Although there are quite a few arguments you can pass to the `to_csv` and `read_csv` methods, there is really only one common use case which you need to know about.\n",
    "\n",
    "First, lets write the DataFrame to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56542e62-3d2f-4e85-9f1f-97ed81af855f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"california_housing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb1064-42c6-40ba-9bb8-ed346a7de8bd",
   "metadata": {},
   "source": [
    "You'll notice that if you have the file browser tab on the left open, that the `california_housing.csv` file will appear and can be viewed in your Jupyter Notebook/Lab instance.\n",
    "\n",
    "Now, lets read it back and make sure it's equal to the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072909e-50e0-4bcd-a241-bf97f5085033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"california_housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80253aed-4d9a-44cb-9f60-49d2a1fc1b79",
   "metadata": {},
   "source": [
    "It is immediately worth noting that some of the `total_bedrooms` column contains some NaN values. These will be problematic to deal with later on, so for now, we're just going to remove any row in which there is at least one NaN value using the `dropna` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d3b98-e659-4b13-9eb1-9e3593869494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbc627-0c76-429e-b849-ee4277975703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(df == df2.dropna()).all().all()  # What did we do here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048c238-0cb5-4c75-b876-4f6ce9a0c375",
   "metadata": {
    "tags": []
   },
   "source": [
    "An interesting subtlety of Python is that `NaN == NaN` is actually _false_. As such, without the `dropna` applied to both DataFrames, the arrays would not be completely equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288f8ae-9577-4fae-95c6-87fdbb7a088d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "float('nan') == float('nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c6015-857e-4599-a555-f91d66fe0b91",
   "metadata": {},
   "source": [
    "Anyways, you can see it's quite easy to save and load Pandas DataFrames. A few interesting things to play with:\n",
    "* What happens if you set `index=False`. when saving the csv?\n",
    "* Explore, in some detail, the comparison between the two DataFrames, including what happens if you don't drop the NaNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d18930-a200-48a2-bdc9-40d8a88334ab",
   "metadata": {},
   "source": [
    "## Accessing DataFrame columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1417f-0b2f-4a77-b74a-6d7bd137c050",
   "metadata": {},
   "source": [
    "Recall that for NumPy arrays you can access columns via slicing. For example, for a two-dimensional array, you can access the 0th column via `arr[:, 0]`. In Pandas, it's even easier. How do we access a column in a DataFrame? How do we even know which columns there are? Lets start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b413475-80d6-4421-a5b4-ce5d00914c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872cb05-48dc-42e0-a48c-d7bb1af1b8b6",
   "metadata": {},
   "source": [
    "Listing the `df.columns` shows the available columns you can access. To then pull that column from the DataFrame, we can simply use the same syntax as dictionary lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20446c04-6451-4a88-9eb2-3f62ecb573b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_rooms = df[\"total_rooms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8fc0b9-d15b-4cfe-9f24-e4df4c55d6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "`total_rooms` is a slice of the DataFrame, called a Series. It can be easily converted into NumPy arrays, and has many of the same methods defined on it that the DataFrame does.\n",
    "\n",
    "Another way to access certain slices of the array can be using the `loc` method, which essentially combines NumPy slicing with dictionary lookup. Here's how you can access the same Series using `loc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3b918-d68f-41bd-beb5-342073302b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(df.loc[:, \"total_rooms\"] == df[\"total_rooms\"]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73607c-897c-46ad-bf6b-f814f709d89c",
   "metadata": {},
   "source": [
    "The final way to access data in a DataFrame is `iloc`. This treats the Pandas Dataframe as, essentially, a NumPy array, and allows for the same lookup and slicing syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e31ba-1d74-41da-8c2d-592651c89379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total_rooms is the 3rd column (zero-indexed) of the dataframe\n",
    "(df.iloc[:, 3] == df[\"total_rooms\"]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31224a63-2ed8-4e3e-be9f-83f13a6823c3",
   "metadata": {},
   "source": [
    "## Adding columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949322c-4e19-478a-80f3-3310eeebd147",
   "metadata": {},
   "source": [
    "The Pandas DataFrame is highly mutable, and provides a very easy syntax for adding and removing columns. For example, to add a new column with the number of rooms per household, we take advantage of NumPy element-wise broadcasting syntax and simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd952434-6892-4797-94c7-53e355968a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"rooms_per_household\"] = df[\"total_rooms\"] / df[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee59f17-d358-4bc6-b663-0c1ee004d08a",
   "metadata": {},
   "source": [
    "If you print `df`, you can see `rooms_per_household` is the last column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c699aa6-bde7-48ad-978c-21889a777bfc",
   "metadata": {},
   "source": [
    "## Removing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25efe5a-50b1-40d7-9322-1fd872121bee",
   "metadata": {},
   "source": [
    "Removing a column is just as easy as adding one, we simply use `drop`. Note that like most operations in Pandas, `drop` is _not_ performed in-place unless specified. To drop the column we just added, in place, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd404d5-b399-4416-9d8b-1520a10a154a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(\"rooms_per_household\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc9fbc-9d3e-4ae9-ac37-577c1d38636a",
   "metadata": {},
   "source": [
    "Printing `df` again will now show that column removed, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a76f3-64c0-49b9-8990-3e69598a3e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
